{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.70-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\python312\\lib\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\python312\\lib\\site-packages (from ultralytics) (3.9.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\fff\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\python312\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\python312\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\python312\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\python312\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\python312\\lib\\site-packages (from ultralytics) (2.2.2+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\python312\\lib\\site-packages (from ultralytics) (0.17.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\python312\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\python312\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\python312\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Using cached ultralytics-8.3.70-py3-none-any.whl (914 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, seaborn, ultralytics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] O sistema nÃ£o pode encontrar o arquivo especificado: 'C:\\\\Python312\\\\Scripts\\\\ultralytics.exe' -> 'C:\\\\Python312\\\\Scripts\\\\ultralytics.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "sys.path.append('./License_Plate_Detection_Pytorch/LPRNet')\n",
    "sys.path.append('./License_Plate_Detection_Pytorch/MTCNN')\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import cvzone\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from MTCNN import *\n",
    "from LPRNet_Test import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import time\n",
    "import easyocr\n",
    "harcascade = \"haarcascade_russian_plate_number.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 7\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     gray_blurred \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(gray, (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m     _, threshold \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(gray_blurred, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY \u001b[38;5;241m+\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "harcascade = \"haarcascade_russian_plate_number.xml\"\n",
    "plate_detector = cv2.CascadeClassifier(harcascade)\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, threshold = cv2.threshold(gray_blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    morph_opening = cv2.morphologyEx(threshold, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(morph_opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(frame, [contour], 0, (0, 255, 0), 2)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.putText(frame, \"Contour\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Edge\", (x + w - 50, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Edges and Contours\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QRNZE33 score:0.9841159525620041\n",
      "BR score:0.972437041308365\n",
      "BR score:0.9662023583554097\n",
      "BR score:0.9700844375614486\n",
      "QRMZE score:0.9662026206865605\n",
      "QRNZE score:0.9663727869921924\n",
      "QRMZE33 score:0.9776517165524792\n",
      "QRMZE33 score:0.9438834897844725\n",
      "BR score:0.9531953214294024\n",
      "BR score:0.9583258550228483\n",
      "BR score:0.9525173945730416\n",
      "BR score:0.9492163827354839\n",
      "BR score:0.9737054261814505\n",
      "BR score:0.9841737862660972\n",
      "BR score:0.9423103812862955\n",
      "BR score:0.9625841570390731\n",
      "BR score:0.9530812848651387\n",
      "QRMZE score:0.9897272592451043\n",
      "BR score:0.9728863728034635\n",
      "QRMZE3 score:0.9759694212078242\n",
      "BR score:0.9627923905414623\n",
      "BR score:0.9625855741160012\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640) # width\n",
    "cap.set(4, 480) #height\n",
    "\n",
    "min_area = 500\n",
    "count = 0\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "def calculate_blur(image, threshold=500):\n",
    "    \"\"\"\n",
    "    Calculate the blur level of an image and check if it meets the acceptance threshold.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image.\n",
    "        threshold (float): The minimum variance of Laplacian to accept the image as \"sharp\".\n",
    "    \n",
    "    Returns:\n",
    "        blur_level (float): The calculated variance of the Laplacian.\n",
    "        is_acceptable (bool): True if the image is sharp enough, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert image to grayscale for calculation\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Laplacian\n",
    "    laplacian = cv2.Laplacian(gray_image, cv2.CV_64F)\n",
    "    \n",
    "    # Calculate the variance (a measure of sharpness)\n",
    "    blur_level = laplacian.var()\n",
    "    \n",
    "    # Check if the blur level meets the threshold\n",
    "    is_acceptable = blur_level > threshold\n",
    "    \n",
    "    return blur_level, is_acceptable\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    plate_cascade = cv2.CascadeClassifier(harcascade)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    plates = plate_cascade.detectMultiScale(img_gray, 1.1, 4)\n",
    "\n",
    "    for (x,y,w,h) in plates:\n",
    "        area = w * h\n",
    "\n",
    "        if area > min_area:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            plate_img = img[y: y+h, x:x+w]\n",
    "\n",
    "            _, acc = calculate_blur(plate_img)\n",
    "            #print(_)\n",
    "            if acc:\n",
    "                #print(_)\n",
    "                result = reader.readtext(img[y: y+h, x:x+w])\n",
    "                if(len(result) > 0 and result[0][2] >.94 ):\n",
    "                    cv2.putText(img, str(result[0][1]) + str(result[0][2]), (x,y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 255), 2)\n",
    "\n",
    "                    print(str(result[0][1]) + \" score:\" + str(result[0][2]))\n",
    "                img_roi = img[y: y+h, x:x+w]\n",
    "                cv2.imshow(\"ROI\", img_roi)\n",
    "\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"plates/scaned_img_\" + str(count) + \".jpg\", img_roi)\n",
    "        cv2.rectangle(img, (0,200), (640,300), (0,255,0), cv2.FILLED)\n",
    "        cv2.putText(img, \"Plate Saved\", (150, 265), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Results\",img)\n",
    "        cv2.waitKey(500)\n",
    "        count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333 427  70  23]\n",
      " [485 427  95  32]\n",
      " [393   3 152  51]\n",
      " [ 27 147 400 133]\n",
      " [182 161 346 115]\n",
      " [202 142 448 149]\n",
      " [451  96  76  26]\n",
      " [186 387 268  89]\n",
      " [417  34 100  33]\n",
      " [416  65 112  37]\n",
      " [467 407 172  57]\n",
      " [260 331 207  69]\n",
      " [411 110 129  43]\n",
      " [587 361  98  33]\n",
      " [467 329 133  44]\n",
      " [390 403 187  62]\n",
      " [217 327 219  73]\n",
      " [161 306 322 108]]\n",
      "CLASSIC score:0.9994004602244408\n",
      "9 score:0.3669645044324312\n",
      "mcnos polu Ã§io score:0.5028053500352884\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "sys.path.append('./License_Plate_Detection_Pytorch/LPRNet')\n",
    "sys.path.append('./License_Plate_Detection_Pytorch/MTCNN')\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import cvzone\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import argparse\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "#from MTCNN import *\n",
    "from LPRNet_Test import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import time\n",
    "import easyocr\n",
    "harcascade = \"haarcascade_russian_plate_number.xml\"\n",
    "img = cv2.imread('car_3.png')\n",
    "\n",
    "reader = easyocr.Reader(['pt'], recog_network='latin_g2', gpu=True)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_blur(image, threshold=500):\n",
    "    \"\"\"\n",
    "    Calculate the blur level of an image and check if it meets the acceptance threshold.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): The input image.\n",
    "        threshold (float): The minimum variance of Laplacian to accept the image as \"sharp\".\n",
    "    \n",
    "    Returns:\n",
    "        blur_level (float): The calculated variance of the Laplacian.\n",
    "        is_acceptable (bool): True if the image is sharp enough, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert image to grayscale for calculation\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Laplacian\n",
    "    laplacian = cv2.Laplacian(gray_image, cv2.CV_64F)\n",
    "    \n",
    "    # Calculate the variance (a measure of sharpness)\n",
    "    blur_level = laplacian.var()\n",
    "    \n",
    "    # Check if the blur level meets the threshold\n",
    "    is_acceptable = blur_level > threshold\n",
    "    \n",
    "    return blur_level, is_acceptable\n",
    "\n",
    "\n",
    "plate_detector = cv2.CascadeClassifier(harcascade)\n",
    "plate_cascade = cv2.CascadeClassifier(harcascade)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Image not found!\")\n",
    "else:\n",
    "    cv2.imshow(\"IMG\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "plates = plate_cascade.detectMultiScale(img_gray, 1.001, 4)\n",
    "print(plates)\n",
    "if len(plates) > 0:\n",
    "    for (x,y,w,h) in plates:\n",
    "        area = w * h\n",
    "    \n",
    "        if area > 100:\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            plate_img = img[y: y+h, x:x+w]\n",
    "    \n",
    "            _, acc = calculate_blur(plate_img)\n",
    "            #print(_)\n",
    "            if acc:\n",
    "                #print(_)\n",
    "                result = reader.readtext(img[y: y+h, x:x+w])\n",
    "                if(len(result) > 0 and result[0][2] >.2):\n",
    "                    cv2.putText(img, str(result[0][1]) + str(result[0][2]), (x,y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 255), 2)\n",
    "    \n",
    "                    print(str(result[0][1]) + \" score:\" + str(result[0][2]))\n",
    "                img_roi = img[y: y+h, x:x+w]\n",
    "                #cv2.imshow(\"ROI\", img_roi)\n",
    "                #cv2.waitKey(0)\n",
    "                #cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "harcascade = \"haarcascade_russian_plate_number.xml\"\n",
    "plate_detector = cv2.CascadeClassifier(harcascade)\n",
    "\n",
    "\n",
    "frame = cv2.imread('car_1.png')\n",
    "if frame is None:\n",
    "    print(\"Error: Image not found!\")\n",
    "else:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, threshold = cv2.threshold(gray_blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    morph_opening = cv2.morphologyEx(threshold, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(morph_opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(frame, [contour], 0, (0, 255, 0), 2)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.putText(frame, \"Contour\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Edge\", (x + w - 50, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Edges and Contours\", frame)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
